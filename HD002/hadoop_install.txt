移除舊的Java
yum -y remove java-*

下載及安裝Java
http://www.oracle.com/technetwork/java/javase/downloads/index.html
rpm -ivh jdk-8u25-linux-x64.rpm

設定Java ~/.bashrc
export JAVA_HOME=/usr/java/jdk1.8.0_25/
export PATH=$PATH:$JAVA_HOME


下載Hadoop
http://apache.stu.edu.tw/hadoop/common/hadoop-2.5.2/hadoop-2.5.2.tar.gz

解壓縮Hadoop
tar -zxvf hadoop-2.5.2.tar.gz

切換成 root 使用者
$ su –

使用visudo 編輯權限
$ visudo 

給予sudo 權限 (於99行處)
tibame	ALL=(ALL)	ALL

新增使用者群組 hadoop
$ sudo groupadd hadoop

新增使用者 hadoop
$ sudo useradd -g hadoop hadoop

將Hadoop 2.5.2 搬移到 /usr/local
sudo mv ~/hadoop-2.5.2 /usr/local/hadoop

更改該目錄權限
 sudo chown –R hadoop:hadoop /usr/local/hadoop


 

如需要密碼，設定
$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa 
$ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys

將設定加入~/.bashrc

export HADOOP_PREFIX=/usr/local/hadoop 
export HADOOP_COMMON_HOME=$HADOOP_PREFIX 
export HADOOP_HDFS_HOME=$HADOOP_PREFIX 
export HADOOP_MAPRED_HOME=$HADOOP_PREFIX 
export HADOOP_YARN_HOME=$HADOOP_PREFIX 
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_PREFIX/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_PREFIX/lib"
export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop 
export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin


$HADOOP_HOME/etc/hadoop/core-site.xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost</value>
</property>
 
$HADOOP_HOME/etc/hadoop/hdfs-site.xml
<property>
   <name>dfs.replication</name>
   <value>1</value>
</property>

$HADOOP_HOME/etc/hadoop/yarn-site.xml
<property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
</property>

$HADOOP_HOME/etc/hadoop/mapred-site.xml
<property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
</property>

嘗試是否可以無密碼登入
ssh localhost

修改/etc/ssh/sshd_config
將PasswordAuthentication?變更為no
service sshd restart

設置無密碼登入
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
chmod 700 ~/.ssh
Chmod 600  ~/.ssh/authorized_keys


修改 hadoop-env.sh
更新JAVA_HOME
vi /usr/local/hadoop/etc/hadoop/hadoop-env.sh
JAVA_HOME=/usr/java/jdk1.8.0_25/

格式化HDFS
hdfs namenode –format

啟用Hadoop
單獨啟用HDFS及YARN
start-dfs.sh
start-yarn.sh

或使用
start-all.sh

Fully Distributed Mode
====================================================================

修改HOSTNAME
sudo hostname master

修改hosts
172.31.9.252    ec2-54-148-213-237.us-west-2.compute.amazonaws.com
172.31.2.65     ec2-54-148-120-134.us-west-2.compute.amazonaws.com
172.31.8.36     ec2-54-68-105-144.us-west-2.compute.amazonaws.com
172.31.11.147   ec2-54-149-224-235.us-west-2.compute.amazonaws.com

確保機器間可以使用Hadoop 身分連線
ssh ec2-54-148-120-134.us-west-2.compute.amazonaws.com

core-site.xml
<property>
  <name>fs.defaultFS</name>
  <value>hdfs://ec2-54-148-213-237.us-west-2.compute.amazonaws.com</value>
</property>
<property>
  <name>hadoop.tmp.dir</name>
  <value>/home/hadoop/local/var/hadoop/tmp/hadoop-${user.name}</value>
</property>

mapred-site.xml
<property>
    <name>mapreduce.jobtracker.staging.root.dir</name>
    <value>/user</value>
</property>

yarn-site.xml
<property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
</property>
<property>
  <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
  <value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<property>
   <name>yarn.resourcemanager.hostname</name>
   <value>ec2-54-148-213-237.us-west-2.compute.amazonaws.com</value>
</property>

hdfs-site.xml
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>

Masters
ec2-54-148-213-237.us-west-2.compute.amazonaws.com

Slaves
ec2-54-148-120-134.us-west-2.compute.amazonaws.com
ec2-54-68-105-144.us-west-2.compute.amazonaws.com
ec2-54-149-224-235.us-west-2.compute.amazonaws.com


hadoop-env.sh
export HADOOP_PID_DIR=/home/hadoop/local/var/hadoop/pids

mapred-env.sh
export HADOOP_MAPRED_PID_DIR=/home/hadoop/local/var/hadoop/pids

拷貝檔案
scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml masters slaves hadoop@ec2-54-148-120-134.us-west-2.compute.amazonaws.com:$HADOOP_PREFIX/etc/hadoop
scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml masters slaves hadoop@ec2-54-68-105-144.us-west-2.compute.amazonaws.com:$HADOOP_PREFIX/etc/hadoop
scp hadoop-env.sh mapred-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml masters slaves hadoop@ec2-54-149-224-235.us-west-2.compute.amazonaws.com:$HADOOP_PREFIX/etc/hadoop



sudo yum install krb5-devel cyrus-sasl-gssapi cyrus-sasl-deve libxml2-devel libxslt-devel mysql mysql-devel openldap-devel python-devel python-simplejson sqlite-devel

